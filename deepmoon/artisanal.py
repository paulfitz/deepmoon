def fetch_messages():
    errors = [
        'CUDA missing or poorly configured or just really hard to find '
        'and I gave up because honestly life is too short for CUDA.',
        'Model expects input of size [32:16:-1:lemon].',
        'Batch normalization resisted. This is not normal.',
        'Dropout dropped out.',
        'Insufficiently connected layer snubbed.',
        'Insufficiently convoluted, investors beginning to catch on.',
        'Forward pass was fake out, passed back instead.',
        'Backpropagation: chain rule turns out to be more of a chain '
        'guideline.',
        'Gradient vanished, authorities alerted.',
        'Insufficient depth.',
        'Insufficient information for meaningful reply.',
        'Out Of Funding.',
        'arxiv paper: peer review not found.',
        'bug-riddled but you will think you just chose '
        'the wrong optimizer.',
        'Slippery search space.',
        'Devasting loss.',
        'Insufficiently objective.',
        'Stagnant pooling method.',
        'Thrown out of stride.',
        'Insufficient activation, call number on card to activate.',
        'Softmax more like Hardmin right now.',
        'Sigmoid is a great name for a dog.',
        'What even is a deep.',
        'You should try SELU.',
        'You have a bad feeling about the batch size.',
        'Optimal hyperparameters found but not logged, redo from start.',
        'You peeped at the test data didn\'t you don\'t lie to me.',
        'Validation loss suspiciously low.',
        'Overfitting is an understatement.',
        'Attention network losing interest.',
        'XGBoost would crush this you know.',
        'What even',
        'Ka-ching! Deep Learning more like Deep Earning am I right.',
        'LSTMs deserve a snappier acronym.',
        'Loop found in recurrent network.',
        'What if the optimum weights are the friends we make along the way.',
        'Hey what if this, but blockchain?',
        'Partial derivative incomplete.',
        'When I was young, all of this was Field Programmable Gate Arrays.',
        'Have you looked at the commit log for darknet recently?',
        'That looks like a Virginian Spotted Owl.',
        'Someone mentioned reinforcement learning.',
        'Hard hat area: exploding gradients.',
        'Just because the outputs are in the range [0-1] and sum to 1 '
        'doesn\'t make them probabilities.',
        'Have you tried looking at this from a Bayesian perspective.',
        'Ensemble of models is being very mean.',
        'Discontinuity in derivati',
        'Twitter says your framework is no longer hot.',
        'The gradient is not the greatiest, I have to tell you.',
        'Yeah, and then the weights will come forth in '
        'blazing optimality and all lesser solutions '
        'will wither in the clear light of the golden '
        'objective.  I say to you all of this will come '
        'to pass.  But not today, today, you have tried '
        'to load a slightly corrupt jpeg with a slightly '
        'out of date version of opencv but I\'m not going to '
        'tell you any of that, I\'m just going to mysteriously '
        'segfault.  But despair not, it is always darkest '
        'before the dawn.',
        'Network has only residual connections.',
        'MNIST is done, drop it, move on, PLEASE.',
        'Feeling adversarial. Want to make something of it?',
        'Learning from self-play sounds a bit dodgy honestly.',
        'Time to install fortran.',
        'I will variationally autoencode you into a bin.',
        'Marvin Minsky.'
    ]
    return errors
